<?xml version='1.0' encoding='utf-8'?>
<doc><id>Coursera_47</id><course_url>https://www.coursera.org/learn/intro-to-deep-learning</course_url><course_name>Introduction to Deep Learning</course_name><course_platform>Coursera</course_platform><course_instructor>Evgeny Sokolov</course_instructor><course_introduction>The goal of this course is to give learners basic understanding of modern neural networks and their applications in computer vision and natural language understanding. The course starts with a recap of linear models and discussion of stochastic optimization methods that are crucial for training deep neural networks. Learners will study all popular building blocks of neural networks including fully connected layers, convolutional and recurrent layers. 
Learners will use these building blocks to define complex modern architectures in TensorFlow and Keras frameworks. In the course project learner will implement deep neural network for the task of image captioning which solves the problem of giving a text description for an input image.

The prerequisites for this course are: 
1) Basic knowledge of Python.
2) Basic linear algebra and probability.

Please note that this is an advanced course and we assume basic knowledge of machine learning. You should understand:
1) Linear regression: mean squared error, analytical solution.
2) Logistic regression: model, cross-entropy loss, class probability estimation.
3) Gradient descent for linear models. Derivatives of MSE and cross-entropy loss functions.
4) The problem of overfitting.
5) Regularization for linear models.

Do you have technical problems? Write to us: coursera@hse.ru</course_introduction><course_category>Browse.Data Science.Machine Learning</course_category><course_tag>Recurrent Neural Network//Tensorflow//Convolutional Neural Network//Deep Learning</course_tag><course_rating>4.6</course_rating><course_orgnization>National Research University Higher School of Economics</course_orgnization><course_chapter>Introduction to optimization//Introduction to neural networks//Deep Learning for images//Unsupervised representation learning//Deep learning for sequences//Final Project</course_chapter><course_sub_chapter>[['Welcome to AML specialization!', 'Course intro', 'Linear regression', 'Linear classification', 'Gradient descent', 'Overfitting problem and model validation', 'Model regularization', 'Stochastic gradient descent', 'Gradient descent extensions'], ['Multilayer perceptron (MLP)', 'Chain rule', 'Backpropagation', 'Efficient MLP implementation', 'Other matrix derivatives', 'What is TensorFlow', 'Our first model in TensorFlow', 'What Deep Learning is and is not', 'Deep learning as a language'], ['Motivation for convolutional layers', 'Our first CNN architecture', 'Training tips and tricks for deep CNNs', 'Overview of modern CNN architectures', 'Learning new tasks with pre-trained CNNs', 'A glimpse of other Computer Vision tasks'], ['Unsupervised learning: what it is and why bother', 'Autoencoders 101', 'Autoencoder applications', 'Autoencoder applications: image generation, data visualization &amp; more', 'Natural language processing primer', 'Word embeddings', 'Generative models 101', 'Generative Adversarial Networks', 'Applications of adversarial approach'], ['Motivation for recurrent layers', 'Simple RNN and Backpropagation', 'The training of RNNs is not that easy', 'Dealing with vanishing and exploding gradients', 'Modern RNNs: LSTM and GRU', 'Practical use cases for RNNs'], ['$null$']]</course_sub_chapter><course_time>Approx. 36 hours to complete</course_time><reviews>['I have completed other ML courses at Coursera, this is one which I will NOT continue.  The lectures, the assignments and the grading are all riddled with mistakes.  Alone that is not a problem -- however the instructors have failed to make corrections. ', 'You should only take this class, if you already know 90-95% of what it of supposed to teach.', "I have started taking this course after completing Andrew Ng's Deep learning Specialization. This course is very hands-on and would be a great addition to any one interested in Machine learning. The programming assignments are harder but are rewarding in asserting the skillset.", 'Alexander Panin has ruined this course with his pronunciation', 'Lectures provide very small amount of material. There is no sense to describe topics like gradient descent in advance course. It would be much better to take just a few topics and describe them in much more details than to speak 5 min about CNN, 10 mins about RNN, etc.', 'Just a theory, no practice at all !!!', "In general the course is good, it gives you the idea of different neural networks, their usage and a bit of their inner math. The only thing I didn't really like: most programming assighnments contain large precoded parts, which are difficult to understand. For me it would be more useful, if assighnments wouldn't be so difficult, but I had to code myself.", 'PROS: Interesting exercises', 'Most video lectures are useless, lecturers are just reading some text from a paper/screen, some of them have english very far away from perfect. Each programming assignment is more about struggling with bugs rather than learning something about ML. Final project is a torture for students without GPU, you spent 5 hours training the model - your final loss was too low. Can you add a test/assertion for the loss function?  ', "Simply this is not a course as it's not teaching anything, but just presenting things you need to study in order to complete the exercises.", 'Useful course, whereas it is not always clear how to complete homeassignments', 'This course is one of the most difficult I have seen but at the same time it is very well structured. Lectures are understandable, one just need some support from other materials to understand a whole content, at least for me. I struggled a bit with a final project but in general, I enjoyed it a lot, I looked forward to it each week, it was challenging and achievable. I recommend it.', 'nice really hard course.', 'This thing is AMAZING. This thing iS no "INTRODUCTION" - IT IS "ADVANCED". ', 'This course gives a great overview of what can be done with DNNs. Topics are well chosen, clearly presented, and a good level of difficulty.', " I think it's the best intro to DL, especially thank you a lot for mathematical explanation of marix/tensor derivatives. Also implementation NN with numpy and gradient descend improvement are my fave tasks. ", "Overall a very good course. Highly informative, and strikes a good balance of the application of neural networks and theoretical background. I should mention that I have studied mathematics to MSc level so I didn't find the mathematical aspects of the course challenging but this is  will vary depending on your own background - previous study of multivariate calculus will help a lot. ", "one of the best courses I have attended. clear explanation, clear examples, amazing quizzes &amp; Programming Assignment this course is advanced level, don't enroll it if you are a new starter.", 'The course is good enough, but lecturer Aleksendr Panin speaks too quickly and anyway with a strong accent. Fast does not mean good', 'i think that the explanations and examples in the notebooks was not always sufficient', "It's good overall.But if you are a beginner ,this course might be very advanced for you.", "This is a good course, though the instructors failed to keep their pace. If possible, I hope the course updates along TensorFlow 2.0 and provides more readings. As mentioned by other students, we don't want to watch videos on gradient descent again and again. I hope the instructors save time to talk more about some state of the art models and more about TensorFlow, links to good readings, and maybe more exercises on gradient descent and other fundamental techniques. ", 'The course indeed gives an introduction to deep learning, but the practical part is discouraging since the "deep learning" part of practical assignments is usually given rather than asked to develop individually.', 'Too much mathematical', 'good course with great lectures  , but the assignments are very painful  to complete , they are not hard but the training of the model takes to much time and the coursera notebook always crushes  , it took me 1 week to finish an assignment after several trials of training the modal , i ended up by using google Colab with accelerated GPU in order to finish the assignments, also the instructions in the assignments are often not very clear. i suggest to reformulate the assignments and delete or modify  the part where you have to train the model and wait several hours to submit the notebook . ']</reviews><reviewers>['By Daniel', 'By Alexey S', 'By Sandeep P', 'By Dmitry', 'By Anna N', 'By Артем ', 'By Darya L', 'By Daniel I', 'By Nikita F', 'By Marco', 'By Oleg O', 'By Vratislav H', 'By Andres V', 'By AJIT R', 'By Erik G', 'By YaMolekula', 'By Lewis B', 'By Anas K', 'By Radishevski V', 'By Федоров Ф', 'By Abhishek S', 'By Meng Z', 'By Igor B', 'By Anupkumar M', 'By HAZEM D']</reviewers><review_date>['Jul 19, 2018', 'Dec 28, 2017', 'Jul 31, 2018', 'Jan 18, 2019', 'Mar 07, 2018', 'Oct 15, 2018', 'Dec 14, 2018', 'May 08, 2018', 'May 09, 2018', 'Feb 11, 2018', 'Dec 01, 2018', 'Nov 05, 2018', 'Nov 23, 2018', 'Feb 28, 2019', 'Apr 13, 2019', 'Jul 27, 2019', 'Jul 22, 2019', 'Jun 02, 2019', 'Nov 27, 2018', 'Nov 18, 2018', 'Jun 12, 2018', 'Jun 08, 2019', 'Feb 08, 2019', 'Oct 11, 2018', 'Jul 04, 2019']</review_date></doc>