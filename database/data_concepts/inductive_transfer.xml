<doc><id>inductive_transfer</id><concept_name>inductive transfer</concept_name><wiki>Transfer learning (TL) is a research problem in machine learning (ML) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem.[1] For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks.  This area of research bears some relation to the long history of psychological literature on transfer of learning, although formal ties between the two fields are limited. From the practical standpoint, reusing or transferring information from previously learned tasks for the learning of new tasks has the potential to significantly improve the sample efficiency of a reinforcement learning agent.[2]
Andrew Ng said in his NIPS 2016 tutorial [3][4] that TL will be next driver of ML commercial success after supervised learning highlight the importance of TL.
In 1993, Lorien Pratt published a paper on transfer in machine learning, formulating the discriminability-based transfer (DBT) algorithm.[5]
In 1997, the journal Machine Learning  published a special issue devoted to transfer learning,[6] and by 1998, the field had advanced to include multi-task learning,[7]  along with a more formal analysis of its theoretical foundations.[8] Learning to Learn,[9] edited by Pratt and Sebastian Thrun, is a 1998 review of the subject.
</wiki></doc>