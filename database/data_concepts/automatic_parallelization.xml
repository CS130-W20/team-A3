<doc><id>automatic_parallelization</id><concept_name>automatic parallelization</concept_name><wiki>Automatic parallelization, also auto parallelization, autoparallelization, or parallelization, the last one of which implies automation when used in context, refers to converting sequential code into multi-threaded or vectorized (or even both) code in order to utilize multiple processors simultaneously in a shared-memory multiprocessor (SMP) machine. The goal of automatic parallelization is to relieve programmers from the hectic and error-prone manual parallelization process.[1] Though the quality of automatic parallelization has improved in the past several decades, fully automatic parallelization of sequential programs by compilers remains a grand challenge due to its need for complex program analysis and the unknown factors (such as input data range) during compilation.[2]
The programming control structures on which autoparallelization places the most focus are loops, because, in general, most of the execution time of a program takes place inside some form of loop.
There are two main approaches to parallelization of loops: pipelined multi-threading and cyclic multi-threading.[3]
For example, consider a loop that on each iteration applies a hundred operations, and runs for a thousand iterations.  This can be thought of as a grid of 100 columns by 1000 rows, a total of 100,000 operations. Cyclic multi-threading assigns each row to a different thread. Pipelined multi-threading assigns each column to a different thread.
This is the first stage where the scanner will read the input source files to identify all static and extern usages. Each line in the file will be checked against pre-defined patterns to segregate into tokens. These tokens will be stored in a file which will be used later by the
grammar engine. The grammar engine will check patterns of tokens that match with pre-defined rules to identify variables, loops, control
statements, functions etc. in the code.
</wiki></doc>