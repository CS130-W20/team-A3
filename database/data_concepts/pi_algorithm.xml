<doc><id>pi_algorithm</id><concept_name>pi algorithm</concept_name><wiki>
Approximations for the mathematical constant pi (&#960;) in the history of mathematics reached an accuracy within 0.04% of the true value before the beginning of the Common Era (Archimedes). In Chinese mathematics, this was improved to approximations correct to what corresponds to about seven decimal digits by the 5th century.
Further progress was not made until the 15th century (Jamsh&#299;d al-K&#257;sh&#299;). Early modern mathematicians reached an accuracy of 35 digits by the beginning of the 17th century (Ludolph van Ceulen), and 126 digits by the 19th century (Jurij Vega), surpassing the accuracy required for any conceivable application outside of pure mathematics.
The record of manual approximation of &#960; is held by William Shanks, who calculated 527 digits correctly in the years preceding 1873. Since the middle of the 20th century, the approximation of &#960; has been the task of electronic digital computers (for a comprehensive account, see Chronology of computation of &#960;). In March 2019 Emma Haruka Iwao, a Google employee from Japan, calculated to a new world record length of 31&#160;trillion digits with the help of the company's cloud computing service.[1]
</wiki></doc>