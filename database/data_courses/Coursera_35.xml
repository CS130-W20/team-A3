<?xml version='1.0' encoding='utf-8'?>
<doc><id>Coursera_35</id><course_url>https://www.coursera.org/learn/competitive-data-science</course_url><course_name>How to Win a Data Science Competition: Learn from Top Kagglers</course_name><course_platform>Coursera</course_platform><course_instructor>Dmitry Ulyanov</course_instructor><course_introduction>If you want to break into competitive data science, then this course is for you! Participating in predictive modelling competitions can help you gain practical experience, improve and harness your data modelling skills in various domains such as credit, insurance, marketing, natural language processing, sales’ forecasting and computer vision to name a few. At the same time you get to do it in a competitive context against thousands of participants where each one tries to build the most predictive algorithm. Pushing each other to the limit can result in better performance and smaller prediction errors. Being able to achieve high ranks consistently can help you accelerate your career in data science.

In this course, you will learn to analyse and solve competitively such predictive modelling tasks. 

When you finish this class, you will:

- Understand how to solve predictive modelling competitions efficiently and learn which of the skills obtained can be applicable to real-world tasks.
- Learn how to preprocess the data and generate new features from various sources such as text and images.
- Be taught advanced feature engineering techniques like generating mean-encodings, using aggregated statistical measures or finding nearest neighbors as a means to improve your predictions.
- Be able to form reliable cross validation methodologies that help you benchmark your solutions and avoid overfitting or underfitting when tested with unobserved (test) data. 
- Gain experience of analysing and interpreting the data. You will become aware of inconsistencies, high noise levels, errors and other data-related issues such as leakages and you will learn how to overcome them. 
- Acquire knowledge of different algorithms and learn how to efficiently tune their hyperparameters and achieve top performance. 
- Master the art of combining different machine learning models and learn how to ensemble. 
- Get exposed to past (winning) solutions and codes and learn how to read them.

Disclaimer : This is not a machine learning course in the general sense. This course will teach you how to get high-rank solutions against thousands of competitors with focus on practical usage of machine learning methods rather than the theoretical underpinnings behind them.

Prerequisites: 
- Python: work with DataFrames in pandas, plot figures in matplotlib, import and train models from scikit-learn, XGBoost, LightGBM.
- Machine Learning: basic understanding of linear models, K-NN, random forest, gradient boosting and neural networks.

Do you have technical problems? Write to us: coursera@hse.ru</course_introduction><course_category>Browse.Data Science.Data Analysis</course_category><course_tag>Data Analysis//Feature Extraction//Feature Engineering//Xgboost</course_tag><course_rating>4.7</course_rating><course_orgnization>National Research University Higher School of Economics</course_orgnization><course_chapter>Introduction &amp; Recap//Feature Preprocessing and Generation with Respect to Models//Final Project Description//Exploratory Data Analysis//Validation//Data Leakages//Metrics Optimization//Advanced Feature Engineering I//Hyperparameter Optimization//Advanced feature engineering II//Ensembling//Competitions go through//Final Project</course_chapter><course_sub_chapter>[['Introduction', 'Meet your lecturers', 'Course overview', 'Competition Mechanics', 'Kaggle Overview [screencast]', 'Real World Application vs Competitions', 'Recap of main ML algorithms', 'Software/Hardware Requirements'], ['Overview', 'Numeric features', 'Categorical and ordinal features', 'Datetime and coordinates', 'Handling missing values', 'Bag of words', 'Word2vec, CNN'], ['Final project overview'], ['Exploratory data analysis', 'Building intuition about the data', 'Exploring anonymized data', 'Visualizations', 'Dataset cleaning and other things to check', 'Springleaf competition EDA I', 'Springleaf competition EDA II', 'Numerai competition EDA'], ['Validation and overfitting', 'Validation strategies', 'Data splitting strategies', 'Problems occurring during validation'], ['Basic data leaks', 'Leaderboard probing and examples of rare data leaks', 'Expedia challenge'], ['Motivation', 'Regression metrics review I', 'Regression metrics review II', 'Classification metrics review', 'General approaches for metrics optimization', 'Regression metrics optimization', 'Classification metrics optimization I', 'Classification metrics optimization II'], ['Concept of mean encoding', 'Regularization', 'Extensions and generalizations'], ['Hyperparameter tuning I', 'Hyperparameter tuning II', 'Hyperparameter tuning III', 'Practical guide', "KazAnova's competition pipeline, part 1", "KazAnova's competition pipeline, part 2"], ['Statistics and distance based features', 'Matrix factorizations', 'Feature Interactions', 't-SNE'], ['Introduction into ensemble methods', 'Bagging', 'Boosting', 'Stacking', 'StackNet', 'Ensembling Tips and Tricks', 'CatBoost 1', 'CatBoost 2'], ['Crowdflower Competition', 'Springleaf Marketing Response', 'Microsoft Malware Classification Challenge', 'Walmart: Trip Type Classification', 'Acquire Valued Shoppers Challenge, part 1', 'Acquire Valued Shoppers Challenge, part 2'], ['$null$']]</course_sub_chapter><course_time>Approx. 48 hours to complete</course_time><reviews>['I am very conflicted about this series, as well as this particular course (How to win a Data Science Competition). Let me try to summarize it. ', 'A looooot of content!!! ', 'I competed this course within almost 3 months, far more time than I planed. The most time I spent on was to create new features via feature engineering and verify the cross-validation method. This course was difficult, but very helpful and inspirational. Thanks to each teacher and tutor!', "Some cool tips on the first week, but then on the second one we have a whole section about how to exploit data leaks on competitions, and that's worth 12% of the final grade. This sucks... If it wasn't part of the advanced machine learning specialization, I wouldn't care, but it is. This plus a peer-graded assignment with really broad criteria really got me thinking about whether it's worth doing it for a verified certificate.", "Assignments are terribly written. Quizzes don't make sense at times.", 'Should have been labeled "How to Cheat a Data Science competition". An entire week is dedicated to Data Leakage and how to exploit it rather than in the spirit of the competition how to create a model that actually solves the problem.', 'extremely bad supported.  ', "Questions are unclear, authors clearly do not understand what they're asking", "This is the first course I've finished on\ncoursera. At the beginning, the motivation of taking this course is only to get\nan better score in Kaggle competition because I major in statistics and \nam interested in data science. But during the processing of learning, I found\nmany important ideas and experience to deal with the real problem and enjoyed\nthe communication with other people from forum and Kaggle, I also aquired some\nspecial experience such as peer review, which is not only very fun but also can\nprovide me different aspects to see the problem I'm dealing with again. Thanks Dmitry\nUlyanov, Alexander\nGuschin, Mikhail\nTrofimov, Dmitry\nAltukhov, and Marios\nMichailidis for sharing your important knowledge and experience with\nus.", '从理论到实践，不错', 'This course is unique, highly recommended to anyone that wants to push their skill with machine learning, the assignments are excellent and super challenging, after completing the final assignment my understanding how to improve an ml model was better, pushing you to understand how to build a machine learning model to be competitive in Kaggle.', 'Great course to learn practical skills. I love the painful final project.', "Great course, truly invaluable information in there, also the hardest i've ever done, took me months and a couple hundred hours. The knowledge and experience you gain is incredible, not for the faint of heart though.", "Really excellent.  Very practical advice from top competitors.  This specialization is much more information-dense than most machine learning MOOCs.  You really get your money's worth.", 'Great course with excellent tutors. 1C Predict Price Competiton - the best InClass Kaggle competition in which I took part.', 'Teaching style is not engaging at all. I am very confused ', 'Content is really good. But delivery is at times incomprehensible. Assignments questions are also not very clear', 'Very interesting course, and the most practical and useful one. However, lecture are usually too theoretical and super-simple, while assignments are tough and very code oriented. So often there is no real connection between the two (except for Dmitry Altukhov). And final project is too difficult in sense that my Alienware 16 RAM was not enough, so I had to go to Google Cloud Platform. Also, I am not sure is anybody who is learning Machine Learning possible to do the final task in "6 hours" as solely runs could last for a day...', "There are too many things need the learner to investigate by themselves. We are here to learn but not guess. And the condition to close the course is very hard to achieve. I'd say it is not a well designed course including contents and how they are organized.", 'Great course!', 'Great Course', "Challenging in a fun way, puts things I've learnt before in a different perspective. Overall very practical knowledge with lots of use-cases and not much theory. it's like an awesome lab in grad school.", 'Отличный курс', 'A must for every data scientist, the courses are amazing and you learn a lot a tips.']</reviews><reviewers>['By Kostyantyn B', 'By Fabrice L', 'By Yu Q', 'By Caio A A O', 'By andy', 'By Nicholas C', 'By Steffen R', 'By Nick', 'By 李继杨霖', 'By yanqiang', 'By Carlos V', 'By Xiukun H', 'By Stephane H', 'By Greg W', 'By Голубев К О', 'By Aman S', 'By Mithun G', 'By Milos V', 'By Lun Y', 'By Ivan S', 'By Amandeep S', 'By robert', 'By Mike K', 'By Louis H']</reviewers><review_date>['Aug 10, 2018', 'Apr 11, 2019', 'Dec 05, 2018', 'Nov 20, 2017', 'Aug 05, 2018', 'Mar 10, 2018', 'Oct 16, 2018', 'Mar 04, 2018', 'Oct 17, 2018', 'Oct 29, 2018', 'Sep 30, 2018', 'Feb 25, 2019', 'Apr 10, 2019', 'Feb 19, 2019', 'Sep 27, 2018', 'Jun 03, 2019', 'Jan 14, 2018', 'Mar 08, 2019', 'May 07, 2019', 'Jan 12, 2019', 'Jan 14, 2019', 'Jan 02, 2019', 'Jan 17, 2019', 'Feb 17, 2019']</review_date></doc>