<?xml version='1.0' encoding='utf-8'?>
<doc><id>Coursera_70</id><course_url>https://www.coursera.org/learn/bayesian-methods-in-machine-learning</course_url><course_name>Bayesian Methods for Machine Learning</course_name><course_platform>Coursera</course_platform><course_instructor>Daniil Polykovskiy</course_instructor><course_introduction>People apply Bayesian methods in many areas: from game development to drug discovery. They give superpowers to many machine learning algorithms: handling missing data, extracting much more information from small datasets. Bayesian methods also allow us to estimate uncertainty in predictions, which is a desirable feature for fields like medicine. 
When applied to deep learning, Bayesian methods allow you to compress your models a hundred folds, and automatically tune hyperparameters, saving your time and money.
In six weeks we will discuss the basics of Bayesian methods: from how to define a probabilistic model to how to make predictions from it. We will see how one can automate this workflow and how to speed it up using some advanced techniques. 
We will also see applications of Bayesian methods to deep learning and how to generate new images with it. We will see how new drugs that cure severe diseases be found with Bayesian methods.

Do you have technical problems? Write to us: coursera@hse.ru</course_introduction><course_category>Browse.Data Science.Machine Learning</course_category><course_tag>Bayesian Optimization//Gaussian Process//Markov Chain Monte Carlo (MCMC)//Variational Bayesian Methods</course_tag><course_rating>4.6</course_rating><course_orgnization>National Research University Higher School of Economics</course_orgnization><course_chapter>Introduction to Bayesian methods &amp; Conjugate priors//Expectation-Maximization algorithm//Variational Inference &amp; Latent Dirichlet Allocation//Markov chain Monte Carlo//Variational Autoencoder//Gaussian processes &amp; Bayesian optimization//Final project</course_chapter><course_sub_chapter>[['Think bayesian &amp; Statistics review', 'Bayesian approach to statistics', 'How to define a model', 'Example: thief &amp; alarm', 'Linear regression', 'Analytical inference', 'Conjugate distributions', 'Example: Normal, precision', 'Example: Bernoulli'], ['Latent Variable Models', 'Probabilistic clustering', 'Gaussian Mixture Model', 'Training GMM', 'Example of GMM training', "Jensen's inequality &amp; Kullback Leibler divergence", 'Expectation-Maximization algorithm', 'E-step details', 'M-step details', 'Example: EM for discrete mixture, E-step', 'Example: EM for discrete mixture, M-step', 'Summary of Expectation Maximization', 'General EM for GMM', 'K-means from probabilistic perspective', 'K-means, M-step', 'Probabilistic PCA', 'EM for Probabilistic PCA'], ['Why approximate inference?', 'Mean field approximation', 'Example: Ising model', 'Variational EM &amp; Review', 'Topic modeling', 'Dirichlet distribution', 'Latent Dirichlet Allocation', 'LDA: E-step, theta', 'LDA: E-step, z', 'LDA: M-step &amp; prediction', 'Extensions of LDA'], ['Monte Carlo estimation', 'Sampling from 1-d distributions', 'Markov Chains', 'Gibbs sampling', 'Example of Gibbs sampling', 'Metropolis-Hastings', 'Metropolis-Hastings: choosing the critic', 'Example of Metropolis-Hastings', 'Markov Chain Monte Carlo summary', 'MCMC for LDA', 'Bayesian Neural Networks'], ['Scaling Variational Inference &amp; Unbiased estimates', 'Modeling a distribution of images', 'Using CNNs with a mixture of Gaussians', 'Scaling variational EM', 'Gradient of decoder', 'Log derivative trick', 'Reparameterization trick', 'Learning with priors', 'Dropout as Bayesian procedure', 'Sparse variational dropout'], ['Nonparametric methods', 'Gaussian processes', 'GP for machine learning', 'Derivation of main formula', 'Nuances of GP', 'Bayesian optimization', 'Applications of Bayesian optimization'], ['$null$']]</course_sub_chapter><course_time>Approx. 39 hours to complete</course_time><reviews>['The topic covered is great but could be improved. I understand that it can be difficult for a foreigner to speak English but that doesn\'t help to understand the rather technical course. Besides, the formula are given just as is with little intuitive explanation. Example to follow is A. Ng\'s ML/ AI course which gives a good tradeoff in terms of rigour vs. intuition. Plus I had to purchase some other off line material to better understand "Pattern recognition and Machine Learning" by C. Bishop - which is excellent -  to better understand many concepts. ', 'Good attempt, but rough around the edges. The instructions don\'t cover all of the content in the quizes. There are "tricks" in the quizes and the answers are not-obvious at times, or there are caveats unknown to you. But you get the answers once you fail and read the reasoning. Unfortunately, the notation is a little sloppy and inconsistent at times throughout the lectures. Examples could be completed further. This is a senior undergraduate or graduate level course and without accompanying reading material you have to take a lot of notes through the lecture, pausing the video often. If you\'re new to this material, the time spent on this course is much greater than the time spent on other Coursera courses due to its high level. I have a PhD in physics, so I have the mathematical capabilities. But I\'m relatively new to Bayesian statistics. This course seems to be covering material form Bishop\'s "Pattern Recognition and Machine Learning" text. ', 'Lots of maths! :). Assignments were very interesting as well.', "This course was really good - it started from easy things for beginners and ended with awesome aplication of bayesian neural networks. Since I have masters in Probability and Statistics I was familiar with most of the stuff and I must thank you fot the mathematics and some proofs. It's hard to find such nice math proofs in today's courses, so it is good for non-mathematicians to the science behind these methods.", 'appreciate the balance of introducing the Bayesian statistics and the application of machine learning. ', 'Great mix of theory and practice, without the unnecessary tutorial-like stuff everyone can look up in their search engine of choice.', 'One of the best in-depth course.', 'Course content is excellent. However I hope it could have had more about MCMC. That part was pretty thin.', 'super helpful and very applicable!', 'Great course with fine lecturers and deep immersion in Bayesian methods', 'Learned a lot from this course. Thanks!', 'A very detailed course for someone who wants to strengthen their statistical background.', 'Awesome. Worth it!', 'Tough but useful!', 'Superb Course', 'clear instruction and great insights to algorithm, I love it. Really regret for lacking the time to finish all the programming assignments. ', 'Many more theoretical formulas and derivations than previous courses of the specialization, which might require quite a bit of probability theory knowledge. But it is really helpful to understand EM and VAE in depth as well as to use GPy/GPyOpt tools in practice. It would be better to have detail explanation for some quizzes. ', "This course course teaches you a lot of useful math. It might be hard to understand at times, but you will get through it. Assignments are good for getting to know python tools which implement mathematical concepts described in lectures. Overall the best course I've taken so far.", 'Excellent course! The perfect balance of clear and relevant material and challenging but reasonable exercises. My only critique would be that one of the lecturers sounds very sleepy.', 'This course is little difficult. But I could find very helpful.', 'Various advanced Machine Learning topics like Bayesian interpretation techniques, probabilistic modelling, variational auto encoders, etc. have been explained in a very intuitive and simple manner. Then the assignments are well designed to make sure one is able to work on the existing packages available.', 'Succinct!', 'Well, this course is really good, very demanding, and rigorous. The main disadvantage is the forum. Chances are that nobody will answer your questions, so be prepared to have a raw experience of learning. But if you are serious, you will eventually finish the course, and learn a lot.', "In terms of quality of the material, this is one of the best courses I've taken from Coursera! Bear in mind that it is an advanced course and requirements are high. So if your math skills is at graduate student level, you can benefit from this course. The topics are very important and applicable. I really liked all the explicit and detailed calculations done step by step, though I can guess many would find them boring.", "Overall it's good. My problem is that most of this material is better suited to lecture notes and not a video. They're forcing it into a video since it's coursera. Couldn't get through a lot of the lectures, used a textbook instead."]</reviews><reviewers>['By Daniel', 'By Adam C', 'By Karishma D', 'By Peter K', 'By Wei X', 'By Radosław B', 'By Anmol G', 'By Zixu Z', 'By Alexander R', 'By Голубев К О', 'By Dongxiao Z', 'By Yanting H', 'By SagarSrinivas', 'By Max P Z', 'By Ertan T', 'By Yu Z', 'By Samuel Y', 'By Mark Z', 'By Luke B', 'By Jayaganesh G', 'By Kuldeep J', 'By Amrith S', 'By Jean M A S', 'By Ehsan M K', 'By Maciej']</reviewers><review_date>['Sep 14, 2018', 'May 15, 2018', 'Mar 25, 2019', 'Sep 25, 2018', 'Aug 27, 2018', 'Dec 31, 2018', 'Dec 06, 2018', 'Dec 02, 2018', 'Nov 12, 2018', 'Oct 19, 2018', 'Oct 11, 2018', 'Sep 18, 2018', 'Sep 29, 2018', 'Apr 02, 2018', 'Apr 26, 2018', 'Mar 30, 2018', 'Mar 26, 2018', 'Jun 04, 2019', 'Jun 07, 2019', 'Nov 18, 2017', 'Apr 04, 2019', 'May 17, 2018', 'Jun 03, 2018', 'Nov 25, 2017', 'Mar 24, 2019']</review_date></doc>