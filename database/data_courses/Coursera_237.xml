<?xml version='1.0' encoding='utf-8'?>
<doc><id>Coursera_237</id><course_url>https://www.coursera.org/learn/probabilistic-graphical-models-2-inference</course_url><course_name>Probabilistic Graphical Models 2: Inference</course_name><course_platform>Coursera</course_platform><course_instructor>Daphne Koller</course_instructor><course_introduction>Probabilistic graphical models (PGMs) are a rich framework for encoding probability distributions over complex domains: joint (multivariate) distributions over large numbers of random variables that interact with each other. These representations sit at the intersection of statistics and computer science, relying on concepts from probability theory, graph algorithms, machine learning, and more. They are the basis for the state-of-the-art methods in a wide variety of applications, such as medical diagnosis, image understanding, speech recognition, natural language processing, and many, many more. They are also a foundational tool in formulating many machine learning problems. 

This course is the second in a sequence of three. Following the first course, which focused on representation, this course addresses the question of probabilistic inference: how a PGM can be used to answer questions. Even though a PGM generally describes a very high dimensional distribution, its structure is designed so as to allow questions to be answered efficiently. The course presents both exact and approximate algorithms for different types of inference tasks, and discusses where each could best be applied. The (highly recommended) honors track contains two hands-on programming assignments, in which key routines of the most commonly used exact and approximate algorithms are implemented and applied to a real-world problem.</course_introduction><course_category>Browse.Data Science.Machine Learning</course_category><course_tag>Inference//Gibbs Sampling//Markov Chain Monte Carlo (MCMC)//Belief Propagation</course_tag><course_rating>4.6</course_rating><course_orgnization>Stanford University</course_orgnization><course_chapter>Inference Overview //Variable Elimination//Belief Propagation Algorithms //MAP Algorithms//Sampling Methods//Inference in Temporal Models//Inference Summary</course_chapter><course_sub_chapter>[['Overview: Conditional Probability Queries', 'Overview: MAP Inference'], ['Variable Elimination Algorithm', 'Complexity of Variable Elimination', 'Graph-Based Perspective on Variable Elimination', 'Finding Elimination Orderings'], ['Belief Propagation Algorithm', 'Properties of Cluster Graphs', 'Properties of Belief Propagation', 'Clique Tree Algorithm - Correctness', 'Clique Tree Algorithm - Computation', 'Clique Trees and Independence', 'Clique Trees and VE', 'BP In Practice', 'Loopy BP and Message Decoding'], ['Max Sum Message Passing', 'Finding a MAP Assignment', 'Tractable MAP Problems', 'Dual Decomposition - Intuition', 'Dual Decomposition - Algorithm'], ['Simple Sampling', 'Markov Chain Monte Carlo', 'Using a Markov Chain', 'Gibbs Sampling', 'Metropolis Hastings Algorithm'], ['Inference in Temporal Models'], ['Inference: Summary']]</course_sub_chapter><course_time>Approx. 23 hours to complete</course_time><reviews>["It's absolutely very very hard but extremely interesting course! Although code assignments always have a lot of small bugs, and it cost me lots of time to find out, but, hey! Everything is the same in school(offline), nothing gonna be perfect. The sampling part is the most difficult stuff to learn so far, and after I tried to review it again and again, combined with other online material, I got those shit done! The only drawback of this course is that not many people active in the forum(Including those TA), maybe that just because only a small number of people enrolled in this course. In short, worth learning!", 'great course, though really advanced. would like a bit more examples especially regarding the coding. worth it overally ', 'Great introduction to inference. Requires some extra reading from the textbook.', "Pretty good course, albeit very dense compared to the first one (which was certainly not trivial). I would give it 5 stars just based on the content, but the programming assignments don't work without significant extra effort. I completed the honors track for the first course, but gave up after spending 4 hours trying to fix HW bugs that were reported 8 months ago. ", 'hope to get some feedbacks about hw or exam', 'Good course, but the material really needs a refresh!', 'not very clear from the top-down level.', 'Very great course!  A lot of things have been learnt.  The lectures, quiz and assignments clear up all key concepts.  Especially, assignments are wonderful!', 'This is a great course', 'Excellent!', 'Great course!  Expect to spend significant time reviewing the material.', 'Awesome class!', 'awesome', "Very interesting course. However, even after completing it with honors, I feel like I don't understand a lot. ", 'Difficult, but it makes you think a lot!', 'Interest but difficult.', "I would have like to complete the honors assignments, unfortunately, I'm not fluent in Matlab. Otherwise, great course!", 'Very interesting, more advanced material', 'Perhaps the best introduction to AI/ML - especially for those who think "the future ain\'t what it used to be"; the mathematical techniques covered by the course form a toolkit which can be easily thought of as "core", i.e. a locus of strength which enables a wide universe of thinking about complex problems (many of which were correctly not thought to be tractable in practice until very recently!)...', None, 'good way to learn PGM,', 'Really a interesting, challenging and great course!', "Had a wonderful and enriching fun filled experience, Thank you Daphne Ma'am", "I kind of like the teacher. She can always explain complicated things in a simple way, though the notes she writes in the slides are all in free style. Loopy belief propagation and dual decomposition are the best things I've learnt in this course. I've met them before in some papers, but I found it extremely hard to understand then. Now I gain some significant intuition of them and I'm ready to do further exploration. Anyway, I'll keep on learning course 3 to achieve my first little goal in courser.", 'Great job Prof. Koller!']</reviews><reviewers>['By Shi Y', 'By george v', 'By Anurag S', 'By Jonathan H', 'By Kaixuan Z', 'By Michel S', 'By Tianyi X', 'By Lik M C', 'By Musalula S', 'By Alireza N', 'By Jerry A R', 'By 王文君', 'By Péter D', 'By Evgeniy Z', 'By Arthur C', 'By chen h', 'By Julio C A D L', 'By Tim R', 'By Rishi C', 'By Alexander K', 'By Wei C', 'By Liu Y', 'By Sriram P', 'By Chan-Se-Yeun', 'By Simon T']</reviewers><review_date>['Dec 16, 2018', 'Nov 28, 2017', 'Nov 08, 2017', 'Aug 04, 2017', 'Dec 05, 2018', 'Jul 14, 2018', 'Feb 23, 2018', 'Feb 03, 2019', 'Aug 02, 2018', 'Jan 12, 2017', 'Dec 22, 2017', 'May 21, 2017', 'Nov 14, 2017', 'Mar 10, 2018', 'Jul 19, 2017', 'Feb 06, 2018', 'Apr 09, 2018', 'Oct 04, 2017', 'Oct 28, 2017', 'Jun 03, 2017', 'Mar 06, 2018', 'Mar 18, 2018', 'Jun 24, 2017', 'Jan 31, 2018', 'Sep 14, 2017']</review_date></doc>