<?xml version='1.0' encoding='utf-8'?>
<doc><id>Coursera_412</id><course_url>https://www.coursera.org/learn/big-data-introduction-ar</course_url><course_name>مقدمة عن البيانات الضخمة</course_name><course_platform>Coursera</course_platform><course_instructor>Ilkay Altintas</course_instructor><course_introduction>مقدمة عن البيانات الضخمة
هل أنت مهتم بزيادة معرفتك بأبرز سمات البيانات الضخمة؟ هذه الدورة التدريبية مخصصة للمستجدين في علوم البيانات والمهتمين بفهم أسباب ظهور عصر البيانات الضخمة. فهي مخصصة لمن يريدون الإلمام بالمصطلحات والمفاهيم الأساسية الخاصة بمشكلات البيانات الضخمة وتطبيقاتها وأنظمتها. إنها لمن يريدون البدء في التفكير بشأن الطريقة التي يمكن أن تفيدهم البيانات الضخمة بها في عملهم أو مسيرتهم المهنية. حيث تتعرض مقدمة عن أحد أكثر أطر العمل الشائعة ألا وهو Hadoop، والذي زاد من سهولة تحليل البيانات الضخمة وإمكانية الوصول إليها، فقد زاد من احتمالية تطوير البيانات الضخمة لعالمنا!

وفي نهاية الدورة التدريبية، ستتمكن مما يلي:

*  وصف أبرز سمات البيانات الضخمة بما في ذلك الأمثلة على مشكلات البيانات الضخمة على أرض الواقع التي تتضمن ثلاثة مصادر أساسية للبيانات الضخمة وهي الأفراد والمؤسسات وأدوات الاستشعار.

* شرح خصائص البيانات الضخمة التي تبدأ بالحرف V مثل (volume (الحجم)، وvelocity (السرعة)، وvariety (التنوع)، وveracity (الصحة)، وvalence (التكافؤ)، وvalue (القيمة)) ولماذا تؤثر كل خاصية من تلك الخصائص في جمع البيانات ومتابعتها وتخزينها وتحليلها والإبلاغ عنها

* الاستفادة بقيمة البيانات الضخمة عن طريق استخدام عملية مكونة من 5 خطوات لهيكلة تحليلك. 

* تحديد المشكلات التي تندرج تحت البيانات الضخمة والتي لا تندرج تحتها، والقدرة على إعادة تشكيل مشكلات البيانات الضخمة مثل مسائل علوم البيانات.

* تقديم تفسير للمكونات الهندسية والنماذج البرمجية التي تستخدم في التحليل القابل للتوسيع للبيانات الضخمة.

* تلخيص ميزات المكونات الأساسية لمكدس Hadoop وقيمتها بما في ذلك مورد YARN ونظام إدارة الوظائف، ونظام ملفات HDFS، ونموذج برمجة MapReduce.

* تثبيت البرامج وتشغيلها باستخدام إطار عمل Hadoop!

هذه الدورة التدريبية موجهة للمستجدين في علوم البيانات.  لا يلزم توافر خبرة برمجية مسبقة، على الرغم من ضرورة توافر القدرة على تثبيت التطبيقات واستخدام الأجهزة الظاهرية لإنجاز الواجبات العملية.  

متطلبات الأجهزة:
(أ) معالج رباعي النواة (يوصى بمعالج يدعم ميزة VT-x أو AMD-V)، 64 بت؛ (ب) ذاكرة وصول عشوائي بحجم 8 جيجابايت؛ (ج) مساحة خالية بحجم 20 جيجابايت. 
طريقة العثور على معلومات الأجهزة: (نظام Windows): افتح النظام عن طريق الضغط على زر Start (بدء التشغيل)، وانقر بزر الفأرة الأيمن على أيقونة Computer (جهاز الكمبيوتر)، ثم انقر على Properties (خصائص)؛ (نظام Mac): افتح Overview (نظرة عامة) عن طريق الضغط على قائمة Apple والنقر على "About This Mac." سيتوفر الحد الأدنى من المتطلبات في معظم أجهزة الكمبيوتر ذات الذاكرة العشوائية سعة 8 جيجابايت والتي تم شراؤها في آخر 3 أعوام. وستحتاج إلى سرعة اتصال عالية بالإنترنت لأنك ستقوم بتنزيل ملفات يصل حجمها إلى 4 جيجابايت.

المتطلبات البرمجية: تعتمد هذه الدورة التدريبية على العديد من الأدوات البرمجية مفتوحة المصدر، ومنها Apache Hadoop. ويمكن تنزيل جميع البرامج المطلوبة وتثبيتها مجانًا.
تتضمن المتطلبات البرمجية ما يلي: Windows 7+ أو Mac OS X 10.10+ أو Ubuntu 14.04+ أو CentOS 6+ VirtualBox 5+.</course_introduction><course_category>Browse.Data Science.Data Analysis</course_category><course_tag /><course_rating /><course_orgnization>University of California San Diego</course_orgnization><course_chapter>مرحبًا//البيانات الضخمة: السبب والمكان//خصائص البيانات الضخمة وأبعاد قابلية التوسع//علوم البيانات: الاستفادة بقيمة البيانات الضخمة//أسس أنظمة البيانات الضخمة وبرمجتها//الأنظمة: بدء استخدام برنامج Hadoop</course_chapter><course_sub_chapter>[['مرحبًا بكم في تخصص البيانات الضخمة', 'التعريف بنفسك والتعرف على الزملاء'], ['ما الذي أوجد عصر البيانات الضخمة؟', 'التطبيقات: العوامل التي تجعل البيانات الضخمة ذات قيمة', 'مثال: إنقاذ الأرواح من خلال البيانات الضخمة', 'مثال: استخدام البيانات الضخمة لمساعدة المرضى', 'قصة نجاح لتحليل الآراء: مساعدة شركة Meltwater لشركة Danone', 'البدء: من أين تأتي البيانات الضخمة؟', 'البيانات التي تنتجها الأجهزة: إنها موجودة في كل مكان ويوجد منها الكثير!', 'البيانات التي تنتجها الأجهزة: المميزات', 'البيانات الضخمة التي ينتجها الأفراد: التحدي غير المنظَّم', 'البيانات الضخمة التي ينتجها الأفراد: ما طريقة استخدامها؟', 'البيانات التي تنتجها المؤسسات: منظَّمة ولكن غالبًا ما تكون منفصلة', 'البيانات التي تنتجها المؤسسات: الفوائد الناتجة عن الدمج مع أنواع البيانات الأخرى', 'المفهوم الأساسي: تكامل البيانات المتنوعة'], ['البدء: خصائص البيانات الضخمة', 'خصائص البيانات الضخمة - الحجم', 'خصائص البيانات الضخمة - التنوع', 'خصائص البيانات الضخمة - السرعة', 'خصائص البيانات الضخمة - الصحة', 'خصائص البيانات الضخمة - التكافؤ', 'الخاصية السادسة: القيمة'], ['علوم البيانات: الاستفادة بقيمة البيانات الضخمة', 'بناء إستراتيجية للبيانات الضخمة', 'كيف تحدث علوم البيانات؟: خمسة مكونات لعلوم البيانات', 'طرح الأسئلة الصحيحة', 'الخطوات المتضمنة في عملية علوم البيانات', 'الخطوة 1: الحصول على البيانات', 'الخطوة 2-أ: استكشاف البيانات', 'الخطوة 2-ب: المعالجة المسبقة للبيانات', 'الخطوة 3: تحليل البيانات', 'الشرائح: الخطوة 4 - التعريف بالنتائج', 'الخطوة 5 - تحويل الأفكار إلى أعمال'], ['البدء - ما أسباب قلقك إزاء الأسس؟', 'ما نظام الملفات الموزعة؟', 'الحوسبة القابلة للتوسع عبر الإنترنت', 'نماذج البرمجة الخاصة بالبيانات الضخمة'], ['Hadoop: لماذا وأين ومَن؟', 'النظام البنائي لبرنامج Hadoop: مرحبًا بكم في حديقة الحيوان!', 'نظام الملفات الموزعة لبرنامج Hadoop: نظام تخزين للبيانات الضخمة', 'YARN: مدير موارد لبرنامج Hadoop', 'MapReduce: برمجة بسيطة من أجل نتائج كبيرة', 'متى ينبغي إعادة النظر بشأن برنامج Hadoop؟', 'الحوسبة السحابية: أداة تمكين مهمة للبيانات الضخمة', 'نماذج الخدمات السحابية: استكشاف الخيارات', 'الاستفادة بقيمة برنامج Hadoop وصور Hadoop الجاهزة', 'نسخ بياناتك إلى نظام الملفات الموزعة لبرنامج Hadoop (HDFS)', 'تشغيل برنامج WordCount']]</course_sub_chapter><course_time>Approx. 13 hours to complete</course_time><reviews>[]</reviews><reviewers>[]</reviewers><review_date>[]</review_date></doc>