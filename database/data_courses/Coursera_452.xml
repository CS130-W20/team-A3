<?xml version='1.0' encoding='utf-8'?>
<doc><id>Coursera_452</id><course_url>https://www.coursera.org/learn/building-resilient-streaming-systems-gcp-es</course_url><course_name>Building Resilient Streaming Systems on Google Cloud Platform en Español</course_name><course_platform>Coursera</course_platform><course_instructor>Google Cloud Training</course_instructor><course_introduction>Este curso de una semana, acelerado y a pedido se basa en Google Cloud Platform Big Data and Machine Learning Fundamentals. Mediante una combinación de clases por video, demonstraciones y labs prácticos, aprenderá a crear canalizaciones de datos de transmisión usando Pub/Sub y Dataflow de Google Cloud a fin de permitir la toma de decisiones en tiempo real. También aprenderá a crear paneles para presentar resultados personalizados para diversas audiencias de partes interesadas.

Requisitos previos:
• Google Cloud Platform Big Data and Machine Learning Fundamentals (o experiencia equivalente)
• Cierto conocimiento sobre Java

Objetivos:
• Comprender los casos prácticos de estadísticas de transmisión en tiempo real
• Usar el servicio de mensajería asíncrona de PubSub de Google Cloud para administrar eventos de datos
• Escribir canalizaciones de transmisión y ejecutar transformaciones cuando sea necesario
• Familiarizarse con ambos extremos de una canalización de transmisión: producción y consumo
• Interoperar Dataflow, BigQuery y Cloud Pub/Sub para lograr una transmisión y un análisis en tiempo real</course_introduction><course_category>Browse.Data Science.Data Analysis</course_category><course_tag /><course_rating /><course_orgnization>Google Cloud</course_orgnization><course_chapter>Módulo 1: Arquitectura de las canalizaciones de estadísticas de transmisión//Módulo 2: Cómo transferir volúmenes variables//Módulo 3: Cómo implementar canalizaciones de transmisión//Módulo 4: Paneles y estadísticas de transmisión//Módulo 5: Cómo manejar los requisitos de capacidad de procesamiento y latencia</course_chapter><course_sub_chapter>[['¿Qué son las transmisiones?', 'Desafío n.º 1: Los volúmenes variables deben contar con capacidad de transferencia para realizar ajustes y ser tolerantes a errores', 'Desafío n.º 2: Es normal que haya latencia', 'Desafío n.º 3: Se necesitan estadísticas instantáneas', 'Análisis de algunos ejemplos de transmisiones'], ['¿Qué es Pub/Sub?', 'Cómo funciona: temas y suscripciones', 'Descripción general del lab', 'Demostración y repaso del lab'], ['Transmisión en Dataflow', 'Desafíos del procesamiento de transmisión', 'Compilación de una canalización de procesamiento de transmisión para los datos de tráfico en vivo', 'Manejo de datos tardíos: marcas de agua, activadores y acumulación', 'Descripción general del lab', 'Demostración y repaso del lab'], ['Paneles y estadísticas de transmisión', 'Descripción general del lab', 'Demostración y repaso del lab'], ['Capacidad de procesamiento y latencia', 'Bigtable: NoSQL de alto rendimiento, rápido y con ajuste de escala automático', 'Cómo hacer transferencias hacia Bigtable', 'Cómo diseñar para Bigtable', 'Cómo hacer transmisiones hacia Bigtable', 'Demostración y repaso del lab', 'Consideraciones de rendimiento', 'Resumen de la especialización Data Engineering on GCP']]</course_sub_chapter><course_time>Approx. 8 hours to complete</course_time><reviews>['  For beginners in GCP  ', 'Un cierre muy completo para el curso, ayudan mucho los ejemplos. Me queda implementar una solución propia con todos los conocimientos adquiridos.']</reviews><reviewers>['By Javier A M P', 'By Carlos M C D']</reviewers><review_date>['Aug 07, 2019', 'Aug 26, 2019']</review_date></doc>