<?xml version='1.0' encoding='utf-8'?>
<doc><id>Coursera_312</id><course_url>https://www.coursera.org/learn/probabilistic-graphical-models-3-learning</course_url><course_name>Probabilistic Graphical Models 3: Learning</course_name><course_platform>Coursera</course_platform><course_instructor>Daphne Koller</course_instructor><course_introduction>Probabilistic graphical models (PGMs) are a rich framework for encoding probability distributions over complex domains: joint (multivariate) distributions over large numbers of random variables that interact with each other. These representations sit at the intersection of statistics and computer science, relying on concepts from probability theory, graph algorithms, machine learning, and more. They are the basis for the state-of-the-art methods in a wide variety of applications, such as medical diagnosis, image understanding, speech recognition, natural language processing, and many, many more. They are also a foundational tool in formulating many machine learning problems. 

This course is the third in a sequence of three. Following the first course, which focused on representation, and the second, which focused on inference, this course addresses the question of learning: how a PGM can be learned from a data set of examples. The course discusses the key problems of parameter estimation in both directed and undirected models, as well as the structure learning task for directed models. The (highly recommended) honors track contains two hands-on programming assignments, in which key routines of two commonly used learning algorithms are implemented and applied to a real-world problem.</course_introduction><course_category>Browse.Data Science.Machine Learning</course_category><course_tag>Algorithms//Expectation–Maximization (EM) Algorithm//Graphical Model//Markov Random Field</course_tag><course_rating>4.6</course_rating><course_orgnization>Stanford University</course_orgnization><course_chapter>Learning: Overview//Review of Machine Learning Concepts from Prof. Andrew Ng's Machine Learning Class (Optional)//Parameter Estimation in Bayesian Networks//Learning Undirected Models//Learning BN Structure//Learning BNs with Incomplete Data//Learning Summary and Final//PGM Wrapup</course_chapter><course_sub_chapter>[['Learning: Overview'], ['Regularization: The Problem of Overfitting ', 'Regularization: Cost Function ', 'Evaluating a Hypothesis ', 'Model Selection and Train Validation Test Sets ', 'Diagnosing Bias vs Variance ', 'Regularization and Bias Variance'], ['Maximum Likelihood Estimation', 'Maximum Likelihood Estimation for Bayesian Networks', 'Bayesian Estimation', 'Bayesian Prediction', 'Bayesian Estimation for Bayesian Networks'], ['Maximum Likelihood for Log-Linear Models', 'Maximum Likelihood for Conditional Random Fields', 'MAP Estimation for MRFs and CRFs'], ['Structure Learning Overview', 'Likelihood Scores', 'BIC and Asymptotic Consistency', 'Bayesian Scores', 'Learning Tree Structured Networks', 'Learning General Graphs: Heuristic Search', 'Learning General Graphs: Search and Decomposability'], ['Learning With Incomplete Data - Overview', 'Expectation Maximization - Intro', 'Analysis of EM Algorithm', 'EM in Practice', 'Latent Variables'], ['Summary: Learning'], ['PGM Course Summary']]</course_sub_chapter><course_time>Approx. 24 hours to complete</course_time><reviews>["I was very lost with the different depths of lectures and assignments in this part of the course. I felt that some places were super involved mathematically and was trying to understand its implication. In other places it felt like a lot of fluff. I would recommend this only if you have taken the other 2 parts. Also Prof. Koller's lectures are quite confounding and monotonous in these more than the other lectures.", 'A great course! Learned a lot.  Especially the assignments are excellent!  Thanks a lot.', 'Bad choice of content. Focus too much on the specific case of table CPDs, missing the big picture. ', "I love this course! It's very difficult but worthy. If you are  looking for the state-of-the-art AI techniques,  PGM doesn't seem to be your best choice. It's some kind of old fashion compared to DL.  I learned a lot about the probability theory through all three courses, and I get better understanding with CRF and HMM. Seriously, it's not a course that will improve your skills or guarantee your successful immediately in ML fields,  but a course that can shape your thoughts, help you think out of box. So if you don't like the black-box in DL, PGM will offer you another brand new perspective to understand this uncertain world.", 'The course is very involved but Daphne makes its palatable. The course open a new world of new possibilities where one can apply PGMs to get concrete understanding of relationships between events and phenomena in any discipline; from social sciences to natural sciences.  ', 'Great course, great assignments I indeed learn much from this course an the whole PGM ialization!', 'Excellent course. Programming assignments are excellent and extremely instructive.  ', 'Great course! It is pretty difficult -  be prepared to study.  Leave plenty of time  before the final exam.', 'very good course for PGM learning and concept for machine learning programming. Just some description for quiz of final exam is somehow unclear, which lead to a little bit confusing.', 'Excellent course! Everyone interested in PGM should consider!', 'Great course! Very informative course videos and challenging yet rewarding programming assignments. Hope that the mentors can be more helpful in timely responding for questions.', None, 'Thank You for all.', 'Awesome course... builds intuitive thinking for developing intelligent algorithms... ', 'Yeah! I managed to finish PGM. I feel ready to explore further. PGM 3 is really helpful. Although many details are not fully discussed, some important intuitions are well illustrated, like EM algorithm and its modification in case of incomplete data. Also, the way the teacher teach set an good example for me to learn to demonstrate complicated things in an easy and vivid way. Thank you so much!', 'Very challenging and fulfilling class!', 'Excellent!', "Had a wonderful Experience, Thank you Daphne Ma'am", None, "The course facilitates learning - and reinforces acquired knowledge through the simple principle of honest effort: students are not given all the answers... but they are 'nudged' in the right direction &amp; guided towards fruitful questions; in a way, it's the perfect course!", 'Very useful course.', 'Great course, though with the progress of ML/DL, content seems a touch outdated. Would ', 'A very demanding course with some glitches in lectures and materials. The topic itself is very interesting, educational and useful.', 'This was a very interesting specialization and beside the theoretical information in the videos I liked very much the programming assignments, which helped very much with understanding more deep the matter. The PAs were also very challenging, especially the ones in the learning part (course 3).', 'Great content.  Explores the machine learning techniques with the tightest coupling of statistics with computer science.  The Probabilistic Graphical Models series is one of the harder MOOCs to pass.  Learners are advised to buy the book and actually read it carefully, preferably in advance of listening to the lectures.  The quality of the course is generally high.  The discussion is  a little muddled at the very end when practical aspects of applying the EM algorithm (for learning when there is missing data) is discussed.']</reviews><reviewers>['By Akshaya T', 'By Lik M C', 'By Antônio H R', 'By Shi Y', 'By Musalula S', 'By Liu Y', 'By ivan v', 'By Jerry A R', 'By llv23', 'By Wenbo Z', 'By Ziheng', 'By Stian F J', 'By Alexander K', 'By Anil K', 'By Chan-Se-Yeun', 'By 王文君', 'By Alireza N', 'By Sriram P', 'By Khalil M', 'By Rishi C', 'By Yang P', 'By Luiz C', 'By Gorazd H R', 'By Niculae I', 'By Allan J']</reviewers><review_date>['Mar 14, 2019', 'Feb 23, 2019', 'Nov 06, 2018', 'Jan 20, 2019', 'Aug 25, 2018', 'Aug 27, 2018', 'Oct 20, 2017', 'Jan 29, 2018', 'Jan 30, 2018', 'Mar 06, 2017', 'Feb 14, 2017', 'Apr 20, 2017', 'Jun 04, 2017', 'Nov 09, 2017', 'Feb 22, 2018', 'Jul 30, 2017', 'Jan 12, 2017', 'Jun 24, 2017', 'Apr 03, 2017', 'Jun 05, 2018', 'Jun 20, 2017', 'Aug 28, 2018', 'Jul 07, 2018', 'May 21, 2017', 'Mar 04, 2017']</review_date></doc>